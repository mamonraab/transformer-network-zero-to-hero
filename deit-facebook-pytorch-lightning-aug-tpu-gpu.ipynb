{"cells":[{"metadata":{},"cell_type":"markdown","source":"# setting kernel type\n\nto use tpu  set training = 'tpu'   for gpu  training = 'gpu'   for cpu training = 'cpu'\n\n# **Note for TPU\n**while these notebook is ok to work in tpu  ,  the xla for pytorch As per they have announced, its still under development and so for operations not supported they automatically switch to CPU so it might get even slower than GPU.\n\nso for some reson in these notebook when using this data sets where  we have  large size of images when  image resize and transformations  it will use cpu for that transformation and do training in tpu and these will cost memory to work around with these either you save images after transformation and read them diractly into the model or  i just skip val phase and also  make batches very small in tpu \nto  use tpu in these dataset\njust set profile='low'  other  can set profile=''high'"},{"metadata":{"trusted":true},"cell_type":"code","source":"training = 'gpu'\nprofile =  'high'  # for this dtata set to use tpu set these var to low","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# install lighting and xla for tpu"},{"metadata":{"trusted":true},"cell_type":"code","source":"if training =='tpu':\n    !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n    !python pytorch-xla-env-setup.py --version 1.7 --apt-packages libomp5 libopenblas-dev","execution_count":9,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"! pip install pytorch-lightning  #==1.1.5\n","execution_count":10,"outputs":[{"output_type":"stream","text":"Requirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.7/site-packages (1.1.5)\nRequirement already satisfied: fsspec[http]>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning) (0.8.5)\nRequirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning) (4.55.1)\nRequirement already satisfied: tensorboard>=2.2.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning) (2.4.1)\nRequirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning) (5.3.1)\nRequirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning) (1.19.5)\nRequirement already satisfied: torch>=1.3 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning) (1.7.0)\nRequirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning) (0.18.2)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from fsspec[http]>=0.8.1->pytorch-lightning) (3.7.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from fsspec[http]>=0.8.1->pytorch-lightning) (2.25.1)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (49.6.0.post20201009)\nRequirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.32.0)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.24.0)\nRequirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.14.0)\nRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.36.2)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.3.3)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.2)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.10.0)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.8.0)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.1)\nRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.15.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.7)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.1.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.6)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (3.3.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->fsspec[http]>=0.8.1->pytorch-lightning) (2020.12.5)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->fsspec[http]>=0.8.1->pytorch-lightning) (2.10)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->fsspec[http]>=0.8.1->pytorch-lightning) (1.26.2)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->fsspec[http]>=0.8.1->pytorch-lightning) (3.0.4)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.0.1)\nRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.3->pytorch-lightning) (3.7.4.3)\nRequirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch>=1.3->pytorch-lightning) (0.6)\nRequirement already satisfied: async-timeout<4.0,>=3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning) (3.0.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning) (5.1.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning) (20.3.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning) (1.6.3)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (3.4.0)\n\u001b[33mWARNING: You are using pip version 21.0; however, version 21.0.1 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install timm","execution_count":11,"outputs":[{"output_type":"stream","text":"Requirement already satisfied: timm in /opt/conda/lib/python3.7/site-packages (0.3.4)\nRequirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.7/site-packages (from timm) (1.7.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm) (0.8.1)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm) (0.18.2)\nRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm) (3.7.4.3)\nRequirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm) (0.6)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm) (1.19.5)\nRequirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (7.2.0)\n\u001b[33mWARNING: You are using pip version 21.0; however, version 21.0.1 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# library  needed by lightining"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nimport torch\nfrom torch.nn import functional as F\nfrom torch import nn\nfrom pytorch_lightning.core import LightningModule\nfrom sklearn.metrics import label_ranking_average_precision_score\n\nprint(torch.__version__)","execution_count":12,"outputs":[{"output_type":"stream","text":"1.7.0\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# other libraarys"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom torchvision import datasets, models, transforms\nfrom torch import nn, optim\nfrom torch.optim import lr_scheduler\nfrom torch.autograd import Variable\nfrom torchvision import datasets, models, transforms  \nfrom torch.utils.data.sampler import SubsetRandomSampler  \nfrom torch.utils.data import Dataset, DataLoader\n\nimport pandas as pd\nimport torch.nn.functional as F\n\nimport time\nimport os\nimport time\nimport random\nfrom datetime import datetime\n\nfrom PIL import Image\nfrom tqdm.notebook import tqdm\nfrom sklearn import model_selection, metrics\n\nimport timm\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import ModelCheckpoint , EarlyStopping\n","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# seeding everthing"},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything(seed):\n    \"\"\"\n    Seeds basic parameters for reproductibility of results\n    \n    Arguments:\n        seed {int} -- Number of the seed\n    \"\"\"\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if training == 'gpu':\n        torch.cuda.manual_seed(seed)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\nseed_everything(1001)","execution_count":14,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# configartions"},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_PATH = \"../input/ranzcr-clip-catheter-line-classification\"\nTRAIN_PATH = \"../input/ranzcr-clip-catheter-line-classification/train/\"\nTEST_PATH = \"../input/ranzcr-clip-catheter-line-classification/test/\"\nMODEL_PATH = (\n    \"../input/vit-base-models-pretrained-pytorch/jx_vit_base_p16_224-80ecf9dd.pth\"\n)\n\n\n\nIMG_SIZE = 384\nif profile =='low':\n    BATCH_SIZE = 8 \n    val_BATCH_SIZE = 2\n    valchecking = 3\n    epoch = 2\n    monit = 'train_loss'\nelse:\n    BATCH_SIZE = 16\n    val_BATCH_SIZE = 16\n    valchecking = 1\n    epoch = 20\n    monit = 'val_loss'","execution_count":15,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# read csv file with pandas"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(os.path.join(DATA_PATH, \"train.csv\"))\ndf.head()","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"                                    StudyInstanceUID  ETT - Abnormal  \\\n0  1.2.826.0.1.3680043.8.498.26697628953273228189...               0   \n1  1.2.826.0.1.3680043.8.498.46302891597398758759...               0   \n2  1.2.826.0.1.3680043.8.498.23819260719748494858...               0   \n3  1.2.826.0.1.3680043.8.498.68286643202323212801...               0   \n4  1.2.826.0.1.3680043.8.498.10050203009225938259...               0   \n\n   ETT - Borderline  ETT - Normal  NGT - Abnormal  NGT - Borderline  \\\n0                 0             0               0                 0   \n1                 0             1               0                 0   \n2                 0             0               0                 0   \n3                 0             0               0                 0   \n4                 0             0               0                 0   \n\n   NGT - Incompletely Imaged  NGT - Normal  CVC - Abnormal  CVC - Borderline  \\\n0                          0             1               0                 0   \n1                          1             0               0                 0   \n2                          0             0               0                 1   \n3                          0             0               1                 0   \n4                          0             0               0                 0   \n\n   CVC - Normal  Swan Ganz Catheter Present  PatientID  \n0             0                           0  ec89415d1  \n1             1                           0  bf4c6da3c  \n2             0                           0  3fc1c97e5  \n3             0                           0  c31019814  \n4             1                           0  207685cd1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>StudyInstanceUID</th>\n      <th>ETT - Abnormal</th>\n      <th>ETT - Borderline</th>\n      <th>ETT - Normal</th>\n      <th>NGT - Abnormal</th>\n      <th>NGT - Borderline</th>\n      <th>NGT - Incompletely Imaged</th>\n      <th>NGT - Normal</th>\n      <th>CVC - Abnormal</th>\n      <th>CVC - Borderline</th>\n      <th>CVC - Normal</th>\n      <th>Swan Ganz Catheter Present</th>\n      <th>PatientID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.2.826.0.1.3680043.8.498.26697628953273228189...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>ec89415d1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.2.826.0.1.3680043.8.498.46302891597398758759...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>bf4c6da3c</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.2.826.0.1.3680043.8.498.23819260719748494858...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3fc1c97e5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.2.826.0.1.3680043.8.498.68286643202323212801...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>c31019814</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.2.826.0.1.3680043.8.498.10050203009225938259...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>207685cd1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# split data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df, valid_df = model_selection.train_test_split(\n    df, test_size=0.2, random_state=42\n)","execution_count":17,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data set class for getting data from path"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n    \nclass TaskDataset(torch.utils.data.Dataset):\n    \"\"\"\n    Helper Class to create the pytorch dataset\n    \"\"\"\n\n    def __init__(self, df, data_path=DATA_PATH, mode=\"train\", transforms=None):\n        super().__init__()\n        self.df_data = df\n        self.data_path = data_path\n        self.transforms = transforms\n        self.mode = mode\n        self.data_dir = TRAIN_PATH if mode == \"train\" else TEST_PATH\n\n    def __len__(self):\n        return len(self.df_data)\n\n    def __getitem__(self, index):\n        img_name = self.df_data.StudyInstanceUID.values[index]\n        label = self.df_data[self.df_data.StudyInstanceUID == img_name].values.tolist()[0][1:-1]\n        img_path = os.path.join(self.data_dir, img_name + \".jpg\" )\n        img =   Image.open(img_path).convert(\"RGB\")\n        label = torch.tensor(label,dtype= torch.float32) \n        if self.transforms is not None:\n            image = self.transforms(img)\n\n        return image, label","execution_count":18,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **  transforming data doing augmention **"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Imagenet means and stds\nmean = [0.485, 0.456, 0.406]\nstd  = [0.229, 0.224, 0.225]\n        \ntransforms_train = transforms.Compose([\n                            transforms.Resize((IMG_SIZE, IMG_SIZE)),\n                         transforms.RandomRotation(45),\n                            transforms.RandomHorizontalFlip(),\n                            transforms.RandomVerticalFlip(),\n                            transforms.RandomResizedCrop(IMG_SIZE),\n                            transforms.ToTensor(),\n                            transforms.Normalize(mean=mean, std=std),\n                           # transforms.Grayscale(num_output_channels=1)\n                        ]\n                    )\n\ntransforms_valid = transforms.Compose(\n                        [\n                            transforms.Resize((IMG_SIZE, IMG_SIZE)),\n                            transforms.ToTensor(),\n                            transforms.Normalize(mean=mean, std=std),\n                            #transforms.Grayscale(num_output_channels=1)\n                        ]\n                    )        \n\n","execution_count":19,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  make datasets and data loaders"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = TaskDataset(train_df, transforms=transforms_train)\nvalid_dataset = TaskDataset(valid_df, transforms=transforms_valid)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df\ndel train_df\ndel valid_df","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader =  DataLoader( dataset=train_dataset,\n        batch_size=BATCH_SIZE, \n      \n        drop_last=True,\n        num_workers=8,shuffle=True)\nvalid_loader =    DataLoader(  dataset=valid_dataset,\n        batch_size=val_BATCH_SIZE ,\n        \n        drop_last=True,\n        num_workers=8,shuffle=False)\n","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs, classes = next(iter(train_loader))  \nprint(classes)","execution_count":23,"outputs":[{"output_type":"stream","text":"tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.],\n        [0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.]])\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# in these code we defin pytorchlightning model\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Mamonmodel(pl.LightningModule):\n    def __init__(self):\n        super().__init__()\n        i = 0\n        self.lr=1e-3\n        self.wd = 1e-6\n        self.schd = 'CosineAnnealingWarmRestarts'\n        #self.best_model_wts = copy.deepcopy(model.state_dict())\n        self.best_loss = np.Inf\n\n        basemodel = torch.hub.load('facebookresearch/deit:main', 'deit_base_patch16_384', pretrained=True)\n        for child in basemodel.blocks.children():\n            if i < 3:\n                for param in child.parameters():\n                    param.requires_grad = False\n            else:\n                for param in child.parameters():\n                    param.requires_grad = True\n            i +=1\n        basemodel.head  =  nn.Sequential( \n                                nn.Dropout(0.25), \n             nn.Linear(768, 11)\n\n                    )\n        self.model = basemodel\n        \n    def forward(self,x):\n        x = self.model(x)\n        return x\n    def training_step(self,batch,batch_idx):\n        x , y = batch\n        y_hat = self.model(x)\n        loss = F.binary_cross_entropy_with_logits(y_hat , y)\n        #scor = label_ranking_average_precision_score(y.cpu(), torch.sigmoid(y_hat).cpu())\n        self.log('train_loss', loss)\n        #self.log('train_score', scor)\n        return loss  \n    def validation_step(self,batch,batch_idx):\n        x , y = batch\n        y_hat = self.model(x)\n        loss = F.binary_cross_entropy_with_logits(y_hat , y)\n        #scor = label_ranking_average_precision_score(y.cpu(), torch.sigmoid(y_hat).cpu())\n        #self.log('val_score', scor)\n        self.log('val_loss', loss) \n        if self.best_loss > loss:\n            self.best_loss = loss\n            torch.save(self.model.state_dict(), 'Deit-bestwigh-ep-'+str(self.current_epoch)+'.pth')\n        return loss    \n    def configure_optimizers(self):\n        optimizer = optim.AdamW(\n            self.model.parameters(), lr=self.lr, weight_decay=self.wd\n        )\n        if self.schd == 'ReduceLROnPlateau':\n            scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.9, patience=3,\n                                          verbose=True)\n        elif self.schd == 'CosineAnnealingLR':\n            scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=0)\n        elif self.schd == 'CosineAnnealingWarmRestarts':\n            scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1, eta_min=0.001, last_epoch=-1) \n\n        return {'optimizer': optimizer, 'lr_scheduler': scheduler  ,  'monitor':monit }\n        ","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# init model\nmemomodel = Mamonmodel()","execution_count":30,"outputs":[{"output_type":"stream","text":"Using cache found in /root/.cache/torch/hub/facebookresearch_deit_main\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n{val_loss:.2f}\n'''\nearly_stop_callback = EarlyStopping(\n   monitor='val_loss',\n    min_delta=0.00,\n   patience=3,\n    verbose=False,\n   mode='min'\n )\nif training == 'gpu':\n    checkpoint_callback = ModelCheckpoint(filename='{epoch}-gpumodel.pth', \n    verbose=True,\n    monitor='val_loss',\n    mode='min')\n    trainer = pl.Trainer(min_epochs=1 , max_epochs=epoch, check_val_every_n_epoch=valchecking,\n            \n                        gpus=-1,callbacks=[checkpoint_callback , early_stop_callback]\n    ) \n    \nelif training == 'tpu':\n    print('now we n tpu')\n    checkpoint_callback = ModelCheckpoint(filename='{epoch}-tpumodel.pth',  \n    verbose=True,\n    monitor=monit,\n    mode='min')\n    trainer = pl.Trainer(tpu_cores=8,min_epochs=1,num_sanity_val_steps=0 , check_val_every_n_epoch=valchecking , max_epochs=epoch,  callbacks=[checkpoint_callback])\nelse:\n    checkpoint_callback = ModelCheckpoint(filename='{epoch}-cpumodel.pth',  \n    verbose=True,\n    monitor='val_loss',\n    mode='min')\n    trainer = pl.Trainer(min_epochs=1 , max_epochs=epoch,check_val_every_n_epoch=valchecking,  callbacks=[checkpoint_callback , early_stop_callback])\n\n    \n\n\ntrainer.fit(memomodel, train_loader , valid_loader)","execution_count":31,"outputs":[{"output_type":"stream","text":"GPU available: True, used: True\nTPU available: None, using: 0 TPU cores\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\n  | Name  | Type              | Params\n--------------------------------------------\n0 | model | VisionTransformer | 86.1 M\n--------------------------------------------\n64.8 M    Trainable params\n21.3 M    Non-trainable params\n86.1 M    Total params\n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"Validation sanity check: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f76e050150b24e56b7a815c339ba2093"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","text":"Epoch 0, global step 1503: val_loss reached 0.28412 (best 0.28412), saving model to \"/kaggle/working/lightning_logs/version_0/checkpoints/epoch=0-gpumodel.pth.ckpt\" as top 1\n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"Validating: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","text":"Epoch 1, global step 3007: val_loss reached 0.28387 (best 0.28387), saving model to \"/kaggle/working/lightning_logs/version_0/checkpoints/epoch=1-gpumodel.pth.ckpt\" as top 1\n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"Validating: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","text":"Epoch 2, step 4511: val_loss was not in top 1\n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"Validating: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","text":"Epoch 3, global step 6015: val_loss reached 0.28219 (best 0.28219), saving model to \"/kaggle/working/lightning_logs/version_0/checkpoints/epoch=3-gpumodel.pth.ckpt\" as top 1\n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"Validating: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","text":"Epoch 4, step 7519: val_loss was not in top 1\n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"Validating: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","text":"Epoch 5, step 9023: val_loss was not in top 1\n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"Validating: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","text":"Epoch 6, step 10527: val_loss was not in top 1\n","name":"stderr"},{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"1"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}