{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **import lib** # \n\nthe main part for bert is in transformers\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.optimizers.schedules import PolynomialDecay\nfrom transformers import TFAutoModel, AutoTokenizer\nimport matplotlib.pyplot as plt\nimport math, re, os\nimport string\n\n# Set seed for experiment reproducibility\nseed = 42\ntf.random.set_seed(seed)\nnp.random.seed(seed)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-27T22:10:26.814871Z","iopub.execute_input":"2021-08-27T22:10:26.81594Z","iopub.status.idle":"2021-08-27T22:10:34.874204Z","shell.execute_reply.started":"2021-08-27T22:10:26.815776Z","shell.execute_reply":"2021-08-27T22:10:34.873196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# define paths for data and  the offline load of transformers lib","metadata":{}},{"cell_type":"code","source":"train_loc = '../input/nlp-getting-started/train.csv'\ntest_loc = '../input/nlp-getting-started/test.csv'\nfile_path = '/kaggle/input/huggingface-bert/'\nMODEL_NAME = \"bert-large-uncased\"\nbatch_size = 32\nepochs = 10","metadata":{"execution":{"iopub.status.busy":"2021-08-27T22:10:34.878031Z","iopub.execute_input":"2021-08-27T22:10:34.878338Z","iopub.status.idle":"2021-08-27T22:10:34.885549Z","shell.execute_reply.started":"2021-08-27T22:10:34.878307Z","shell.execute_reply":"2021-08-27T22:10:34.884355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Read","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(train_loc)\ntest_df = pd.read_csv(test_loc)\nprint('training items ' + str(train_df.shape[0]) )\nprint('test items ' + str(test_df.shape[0]) )","metadata":{"execution":{"iopub.status.busy":"2021-08-27T22:10:43.08037Z","iopub.execute_input":"2021-08-27T22:10:43.080845Z","iopub.status.idle":"2021-08-27T22:10:43.158188Z","shell.execute_reply.started":"2021-08-27T22:10:43.080811Z","shell.execute_reply":"2021-08-27T22:10:43.157105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T22:10:48.007611Z","iopub.execute_input":"2021-08-27T22:10:48.00796Z","iopub.status.idle":"2021-08-27T22:10:48.039989Z","shell.execute_reply.started":"2021-08-27T22:10:48.007931Z","shell.execute_reply":"2021-08-27T22:10:48.038752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"maxlenght = train_df.text.map(len).max()\nmaxlenght_test = test_df.text.map(len).max()\n\nprint(f'maxmum str lenght in training  is : {maxlenght}\\n   max str lunght in test is : {maxlenght_test}\\n')","metadata":{"execution":{"iopub.status.busy":"2021-08-27T22:10:49.599635Z","iopub.execute_input":"2021-08-27T22:10:49.6Z","iopub.status.idle":"2021-08-27T22:10:49.619012Z","shell.execute_reply.started":"2021-08-27T22:10:49.599969Z","shell.execute_reply":"2021-08-27T22:10:49.617682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# very simple cleaning  function","metadata":{}},{"cell_type":"code","source":"def clean(title):\n\n    title = re.sub(r\"\\-\",\" \",title)\n    title = re.sub(r\"\\+\",\" \",title)\n    title = re.sub (r\"&\",\"and\",title)\n    title = re.sub(r\"\\|\",\" \",title)\n    title = re.sub(r\"\\\\\",\" \",title)\n    title = re.sub(r\"\\W\",\" \",title)\n    title = title.lower()\n    for p in string.punctuation :\n        title = re.sub(r\"f{p}\",\" \",title)\n    \n    title = re.sub(r\"\\s+\",\" \",title)\n    \n    return title","metadata":{"execution":{"iopub.status.busy":"2021-08-27T22:10:51.71254Z","iopub.execute_input":"2021-08-27T22:10:51.712893Z","iopub.status.idle":"2021-08-27T22:10:51.720592Z","shell.execute_reply.started":"2021-08-27T22:10:51.712862Z","shell.execute_reply":"2021-08-27T22:10:51.719171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"text\"] = train_df[\"text\"].map(clean)\ntest_df[\"text\"] = test_df[\"text\"].map(clean)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-27T22:10:54.280059Z","iopub.execute_input":"2021-08-27T22:10:54.280449Z","iopub.status.idle":"2021-08-27T22:10:55.049643Z","shell.execute_reply.started":"2021-08-27T22:10:54.280384Z","shell.execute_reply":"2021-08-27T22:10:55.048427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**function to do tokenize and padd or truncation on the data **","metadata":{}},{"cell_type":"code","source":"def tokeniz_dataset(tokenizer,max_len):\n\n    return {\n        \"train\": {\n            \"data\": tokenizer(list(train_df[\"text\"].values), padding = \"max_length\", max_length = max_len, truncation = True, return_tensors = \"tf\").data,\n            \"labels\": train_df[\"target\"].values,\n        },\n        \"test\": {\n            \"data\": tokenizer(list(test_df[\"text\"].values), padding = \"max_length\", max_length = max_len, truncation = True, return_tensors = \"tf\").data\n        }\n    }","metadata":{"execution":{"iopub.status.busy":"2021-08-27T22:11:05.281007Z","iopub.execute_input":"2021-08-27T22:11:05.281362Z","iopub.status.idle":"2021-08-27T22:11:05.288042Z","shell.execute_reply.started":"2021-08-27T22:11:05.281331Z","shell.execute_reply":"2021-08-27T22:11:05.286699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define the model \n\n**bert + our own linear layers**","metadata":{}},{"cell_type":"code","source":"class ClassifModel(tf.keras.Model):\n\n    def __init__(self, checkpoint):\n        super(ClassifModel, self).__init__()\n        \n        self.base_model = TFAutoModel.from_pretrained(checkpoint)\n        #self.base_model.trainable = False  # Freeze the outer model\n\n        self.flatten = layers.Flatten()\n        \n        self.dropout1 = layers.Dropout(rate = 0.25)\n        self.linear1 = layers.Dense(units = 1024, kernel_regularizer = \"l1_l2\")\n        self.batchNorm1 = layers.BatchNormalization()\n        self.activation1 = layers.Activation(\"relu\")\n        \n        self.out = layers.Dense(units = 1, activation = \"sigmoid\")\n\n    def call(self, inputs, training = False):\n        x = self.base_model(inputs).last_hidden_state\n        x = self.flatten(x)\n        \n        x = self.dropout1(x) if training else x\n        x = self.linear1(x)\n        x = self.batchNorm1(x)\n        x = self.activation1(x)\n\n        x = self.out(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-08-27T22:13:06.462636Z","iopub.execute_input":"2021-08-27T22:13:06.463044Z","iopub.status.idle":"2021-08-27T22:13:06.471705Z","shell.execute_reply.started":"2021-08-27T22:13:06.463002Z","shell.execute_reply":"2021-08-27T22:13:06.47057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**f1 score for the compution porpuse **","metadata":{}},{"cell_type":"code","source":"class F1_score(tf.keras.metrics.Metric):\n\n    def __init__(self, name = \"f1_score\", **kwargs):\n        super(F1_score, self).__init__(name = name, **kwargs)\n        \n        self.precision = tf.keras.metrics.Precision()\n        self.recall = tf.keras.metrics.Recall()\n        \n    def update_state(self, y_true, y_pred, sample_weight = None):\n        self.precision.update_state(y_true, y_pred, sample_weight)\n        self.recall.update_state(y_true, y_pred, sample_weight)\n        \n    def reset_states(self):\n        self.precision.reset_states()\n        self.recall.reset_states()\n        \n    def result(self):\n        return 2 / ((1 / self.precision.result()) + (1 / self.recall.result()))","metadata":{"execution":{"iopub.status.busy":"2021-08-27T22:13:07.987657Z","iopub.execute_input":"2021-08-27T22:13:07.988045Z","iopub.status.idle":"2021-08-27T22:13:07.997707Z","shell.execute_reply.started":"2021-08-27T22:13:07.987998Z","shell.execute_reply":"2021-08-27T22:13:07.996283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# learning rate schudler ","metadata":{}},{"cell_type":"code","source":"def lrfn(epoch, bs=batch_size, epochs=epochs):\n    # Config\n    LR_START = 1e-5\n    LR_MAX = 2e-3\n    LR_FINAL = 1e-5\n    LR_RAMPUP_EPOCHS = 4\n    LR_SUSTAIN_EPOCHS = 0\n    DECAY_EPOCHS = epochs  - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS - 1\n    LR_EXP_DECAY = (LR_FINAL / LR_MAX) ** (1 / (epochs - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS - 1))\n\n    if epoch < LR_RAMPUP_EPOCHS: # exponential warmup\n        lr = LR_START + (LR_MAX + LR_START) * (epoch / LR_RAMPUP_EPOCHS) ** 2.5\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS: # sustain lr\n        lr = LR_MAX\n    else: # cosine decay\n        epoch_diff = epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS\n        decay_factor = (epoch_diff / DECAY_EPOCHS) * math.pi\n        decay_factor= (tf.math.cos(decay_factor).numpy() + 1) / 2        \n        lr = LR_FINAL + (LR_MAX - LR_FINAL) * decay_factor\n\n    return lr\n","metadata":{"execution":{"iopub.status.busy":"2021-08-27T22:13:09.480147Z","iopub.execute_input":"2021-08-27T22:13:09.480624Z","iopub.status.idle":"2021-08-27T22:13:09.489803Z","shell.execute_reply.started":"2021-08-27T22:13:09.480593Z","shell.execute_reply":"2021-08-27T22:13:09.488283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plots the learning rate schedule\ndef show_lr_schedule(bs=batch_size, epochs=epochs):\n    rng = [i for i in range(epochs)]\n    y = [lrfn(x, bs=bs, epochs=epochs) for x in rng]\n    x = np.arange(epochs)\n    x_axis_labels = list(map(str, np.arange(1, epochs+1)))\n    print('init lr {:.1e} to {:.1e} final {:.1e}'.format(y[0], max(y), y[-1]))\n    \n    plt.figure(figsize=(30, 10))\n    plt.xticks(x, x_axis_labels, fontsize=16) # set tick step to 1 and let x axis start at 1\n    plt.yticks(fontsize=16)\n    plt.plot(rng, y)\n    plt.grid()\n    plt.show()\n    \nshow_lr_schedule()","metadata":{"execution":{"iopub.status.busy":"2021-08-27T22:13:10.867559Z","iopub.execute_input":"2021-08-27T22:13:10.867899Z","iopub.status.idle":"2021-08-27T22:13:19.209586Z","shell.execute_reply.started":"2021-08-27T22:13:10.867863Z","shell.execute_reply":"2021-08-27T22:13:19.20847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# init tokenizer and model ","metadata":{}},{"cell_type":"code","source":"\ntokenizer = AutoTokenizer.from_pretrained('../input/huggingface-bert/bert-large-uncased' )\nmodel = ClassifModel('../input/huggingface-bert/bert-large-uncased')\nloss = BinaryCrossentropy()\nmodel.compile(loss = loss, optimizer = tf.keras.optimizers.Adam(), metrics = [\"accuracy\", F1_score()])\ntokenized_dataset = tokeniz_dataset(tokenizer,80)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T22:13:38.028513Z","iopub.execute_input":"2021-08-27T22:13:38.028933Z","iopub.status.idle":"2021-08-27T22:13:54.48404Z","shell.execute_reply.started":"2021-08-27T22:13:38.0289Z","shell.execute_reply":"2021-08-27T22:13:54.482897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Start training ","metadata":{}},{"cell_type":"code","source":"checkpoint_filepath = './modebest-stlr.h5'\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    save_weights_only=True,\n    monitor='val_f1_score',\n    mode='max',\n    save_best_only=True)\nearlystop = tf.keras.callbacks.EarlyStopping(\n    monitor='val_f1_score', patience=3,  \n    mode='max' \n)\nlr_callback = tf.keras.callbacks.LearningRateScheduler(lambda epoch: lrfn(epoch, epochs=epochs), verbose=1)\nhistory = model.fit(\n    x = tokenized_dataset[\"train\"][\"data\"],\n    y = tokenized_dataset[\"train\"][\"labels\"],\n    batch_size = batch_size,\n    epochs = epochs,\n    validation_split = 0.2, callbacks=[model_checkpoint_callback , earlystop , lr_callback]\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T22:14:00.461581Z","iopub.execute_input":"2021-08-27T22:14:00.461956Z","iopub.status.idle":"2021-08-27T22:31:46.396932Z","shell.execute_reply.started":"2021-08-27T22:14:00.461895Z","shell.execute_reply":"2021-08-27T22:31:46.395762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nplt.figure(figsize = (14, 14))\n\n\nplt.plot(history.history[\"f1_score\"], label = \"f1_score\")\nplt.plot(history.history[\"val_f1_score\"], label = \"val_f1_score\")\nplt.title(\"F1 Score\")\nplt.ylabel(\"F1 Score\")\nplt.xlabel(\"Epoch\")\nplt.legend(loc = \"best\")","metadata":{"execution":{"iopub.status.busy":"2021-08-27T22:31:46.399182Z","iopub.execute_input":"2021-08-27T22:31:46.399709Z","iopub.status.idle":"2021-08-27T22:31:46.688674Z","shell.execute_reply.started":"2021-08-27T22:31:46.399665Z","shell.execute_reply":"2021-08-27T22:31:46.687313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# load best model and make prediactions","metadata":{}},{"cell_type":"code","source":"model.load_weights(checkpoint_filepath)\n\npredictions = model.predict(tokenized_dataset[\"test\"][\"data\"], verbose = True)\npredictions = np.where(predictions >= 0.5, 1, 0)\npredictions","metadata":{"execution":{"iopub.status.busy":"2021-08-27T22:31:46.691073Z","iopub.execute_input":"2021-08-27T22:31:46.691565Z","iopub.status.idle":"2021-08-27T22:32:30.659825Z","shell.execute_reply.started":"2021-08-27T22:31:46.691519Z","shell.execute_reply":"2021-08-27T22:32:30.65858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submissions = test_df.drop(labels = [\"keyword\", \"location\", \"text\"], axis = 1)\nsubmissions[\"target\"] = predictions\nsubmissions.to_csv(\"submissions.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T22:32:30.663273Z","iopub.execute_input":"2021-08-27T22:32:30.663655Z","iopub.status.idle":"2021-08-27T22:32:30.68908Z","shell.execute_reply.started":"2021-08-27T22:32:30.663623Z","shell.execute_reply":"2021-08-27T22:32:30.687801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}